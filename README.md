# ğŸµ Image-to-Music Recommender

**AI-Powered Music Recommendation System Based on Image Mood Analysis**

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Gradio](https://img.shields.io/badge/Gradio-4.0+-orange.svg)](https://gradio.app/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“– Overview

An intelligent music recommendation system that analyzes the emotional atmosphere of images using multimodal AI and recommends a music based on it.

### ğŸ¯ Key Features

#### ğŸ”§ Music Database Building (Setup)
- ğŸ“¦ **Music Vectorization**: Convert audio files to 512-dimensional embeddings using CLAP
- ğŸ’¾ **Vector Database**: Pre-compute and store music embeddings for fast retrieval
- ğŸµ **Metadata Management**: Organize tracks with title, mood, and genre tags
- â• **Easy Addition**: Add new music files -> rebuild database

#### ğŸš€ Music Recommendation (Real-time)
- ğŸ–¼ï¸ **Image Analysis**: Automatic image understanding using BLIP
- ğŸµ **Text Enhancement**: Augment captions with mood-related keywords
- ğŸµ **Multimodal Matching**: Cross-modal embedding with CLAP (Text Encoder)
- ğŸ“Š **Vector Search**: Cosine similarity-based retrieval
- ğŸ¨ **Interactive UI**: Simply web interface built with Gradio
- ğŸ§ **Instant Preview**: Real-time audio playback of recommended tracks

## ğŸ› ï¸ Technology Stack

### AI/ML Framework
- **PyTorch** - Deep learning framework
- **Transformers** (Hugging Face) - Pre-trained model hub
- **BLIP** (Salesforce) - Bootstrapping Language-Image Pre-training
- **CLAP** (LAION) - Contrastive Language-Audio Pre-training

### Audio Processing
- **librosa** - Audio analysis and feature extraction

### Web Framework
- **Gradio** - Rapid UI development for ML models

## ğŸš€ Quick Start

### Prerequisites

```bash
Python 3.9+
pip
```

### Installation

```bash
# Clone the repository
git clone https://github.com/choi8616/music_mood_analyzer.git
cd music-mood-analyzer

# Install dependencies
pip install -r requirements.txt
```

### Running the Application

#### Web UI (Recommended)

```bash
python app.py
```

Then open your browser and navigate to `http://localhost:7860`

#### CLI Interface

```bash
# Basic usage
python recommend.py path/to/image.jpg

# Get top 10 recommendations
python recommend.py path/to/image.jpg --topk 10

# Auto-play the top result (macOS only)
python recommend.py path/to/image.jpg --play
```

## ğŸ“‚ Project Structure

```
music-mood-analyzer/
â”œâ”€â”€ app.py                          # Gradio web interface (main)
â”œâ”€â”€ recommend.py                    # CLI interface
â”œâ”€â”€ image_to_vector.py              # Image â†’ Vector conversion
â”œâ”€â”€ music_to_vector.py              # Audio â†’ Vector & DB constructor
â”œâ”€â”€ music_database.npy              # Vector database (N, 512)
â”œâ”€â”€ music_database_metadata.json    # Metadata (title, mood, genre)
â”œâ”€â”€ processed_music/                # Processed audio files
â”‚   â”œâ”€â”€ game_1.mp3
â”‚   â”œâ”€â”€ lofi_1.mp3
â”‚   â””â”€â”€ ...
â”œâ”€â”€ new_music/                      # New music to be converted
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ§  How It Works

### Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input Image   â”‚  (e.g., sunset.jpg)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BLIP Image Captioning          â”‚
â”‚  Output: "a sunset over ocean"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Text Enhancement               â”‚
â”‚  + ", atmospheric, mood, ..."   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLAP Text Encoder              â”‚
â”‚  Output: [0.23, -0.45, ...]     â”‚  (512-dim embedding)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cosine Similarity Search       â”‚
â”‚  Compare with Music Database    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Top-K Results                  â”‚
â”‚  1. lofi_1.mp3    (0.8234)      â”‚
â”‚  2. piano_2.mp3   (0.7891)      â”‚
â”‚  3. house_1.mp3   (0.7654)      â”‚
â”‚  ...                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technical Details

1. **Image Captioning (BLIP)**
   - Converts images to descriptive text
   - Model: `Salesforce/blip-image-captioning-base`
   - Output: Natural language description

2. **Caption Enhancement**
   - Adds mood-related keywords
   - Example: `"{caption}, atmospheric, mood, cinematic"`

3. **Text Embedding (CLAP)**
   - Encodes text into 512-dimensional vector
   - Model: `laion/clap-htsat-unfused`
   - Shared embedding space with audio

4. **Audio Database**
   - Pre-computed audio embeddings (CLAP audio encoder)
   - L2-normalized for cosine similarity

5. **Similarity Search**
   - Computes: `similarity = query_vector @ database_vectors.T`
   - Returns top-K highest scores

## ğŸ“Š Performance

- **Inference Speed**: ~3 seconds (CPU)
- **Music Database Size**: 10 tracks
- **Embedding Dimension**: 512
- **Similarity Metric**: Cosine Similarity

## ğŸ“ Key Learnings

### 1. Multimodal AI
Understanding how to match different modalities(image, text, audio) using shared embedding spaces.

### 2. Vector Similarity Search
Implementing efficient similarity retrieval in high-dimensional vector spaces.

### 3. Foundation Models
Leveraging large-scale pre-trained models (BLIP, CLAP) for downstream tasks.

### 4. Rapid Prototyping
Building production ready web interfaces quickly with Gradio.

## ğŸ”® Future Enhancements

- [ ] Expand music database (more tracks)
- [ ] Enhance frontend (fix errors, add feature of playing music when track is clicked)
- [ ] Display image analysis on screen
- [ ] Organize backend and README completely

## ğŸ“¸ Screenshots

### Main Interface

### Upload & Analysis

### Recommendation Results

## ğŸ¥ Demo


## ğŸ“¦ Adding New Music

```bash
# 1. Place audio files in new_music/
cp your_song.mp3 new_music/

# 2. Rebuild the database
python music_to_vector.py

# 3. Restart the app
python app.py
```

## ğŸ§ª Testing

```bash
# Test with sample images
python recommend.py test_images/sunset.jpg
python recommend.py test_images/forest.jpg
python recommend.py test_images/city.jpg
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **BLIP**: [Salesforce Research](https://github.com/salesforce/BLIP)
- **CLAP**: [LAION](https://github.com/LAION-AI/CLAP)
- **Gradio**: [Gradio Team](https://gradio.app/)
- **Hugging Face**: [Transformers Library](https://huggingface.co/docs/transformers/)

## ğŸ‘¤ Author

**Your Name**
- GitHub: [@yourname](https://github.com/yourname)
- LinkedIn: [Your Profile](https://linkedin.com/in/yourname)
- Email: your.email@example.com

## ğŸ“ˆ Project Status

ğŸš€ **Active Development** - This project is currently being enhanced with new features.

---

<div align="center">

â­ **If you found this project interesting, please consider giving it a star!** â­

</div>