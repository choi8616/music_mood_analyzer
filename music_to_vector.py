import os
import json
import numpy as np
import torch
from transformers import ClapModel, ClapProcessor
import librosa
import warnings
warnings.filterwarnings('ignore')

class MusicDatabaseBuilder:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"Running on {self.device}...")
        
        # íŒŒíŠ¸ë„ˆì™€ ë™ì¼í•œ CLAP ëª¨ë¸ ì‚¬ìš© (í•„ìˆ˜!)
        print("Loading CLAP (Audio Encoder)...")
        self.clap_model = ClapModel.from_pretrained("laion/clap-htsat-unfused").to(self.device)
        self.clap_processor = ClapProcessor.from_pretrained("laion/clap-htsat-unfused")
        print("âœ… CLAP ë¡œë“œ ì™„ë£Œ\n")
    
    def audio_to_vector(self, audio_path, sample_rate=48000, duration=30):
        """
        ìŒì•… íŒŒì¼ -> CLAP ì˜¤ë””ì˜¤ ì„ë² ë”© (512 dim, Normalized)
        íŒŒíŠ¸ë„ˆì˜ í…ìŠ¤íŠ¸ ë²¡í„°ì™€ ë™ì¼í•œ ê³µê°„ì— ë§¤í•‘ë©ë‹ˆë‹¤.
        """
        try:
            print(f"   ğŸ“‚ ë¡œë”©: {os.path.basename(audio_path)}")
            
            # ì˜¤ë””ì˜¤ ë¡œë“œ (CLAPì€ 48kHz ê¶Œì¥)
            audio, sr = librosa.load(audio_path, sr=sample_rate, mono=True)
            print(f"   â±ï¸  ì›ë³¸ ê¸¸ì´: {len(audio)/sr:.1f}ì´ˆ")
            
            # í•˜ì´ë¼ì´íŠ¸ ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì¤‘ê°„ 30ì´ˆ)
            max_length = sample_rate * duration
            if len(audio) > max_length:
                start = (len(audio) - max_length) // 2
                audio = audio[start:start + max_length]
                print(f"   âœ‚ï¸  {duration}ì´ˆë¡œ ìë¦„ (ì¤‘ê°„ ë¶€ë¶„)")
            
            # CLAP ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            inputs = self.clap_processor(
                audio=audio,
                sampling_rate=sample_rate,
                return_tensors="pt"
            ).to(self.device)
            
            with torch.no_grad():
                audio_features = self.clap_model.get_audio_features(**inputs)
            
            # Extract the tensor from the output object
            if hasattr(audio_features, 'pooler_output'):
                audio_features = audio_features.pooler_output
            else:
                raise ValueError("Unexpected output format from get_audio_features")
            
            # ì •ê·œí™” (íŒŒíŠ¸ë„ˆ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ!)
            audio_features = audio_features / audio_features.norm(p=2, dim=-1, keepdim=True)
            
            vector = audio_features.cpu().numpy().flatten()
            print(f"   âœ… ë²¡í„° ìƒì„± ì™„ë£Œ: {vector.shape}\n")
            
            return vector
            
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}\n")
            return None
    
    def build_database(self, music_folder="music", output_prefix="music_database"):
        """
        ìŒì•… í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ ë²¡í„°í™”í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
        """
        # ì§€ì›í•˜ëŠ” ì˜¤ë””ì˜¤ í¬ë§·
        audio_extensions = ['.mp3', '.wav', '.flac', '.m4a', '.ogg']
        
        # ìŒì•… íŒŒì¼ ì°¾ê¸°
        music_files = []
        for root, dirs, files in os.walk(music_folder):
            for file in files:
                if any(file.lower().endswith(ext) for ext in audio_extensions):
                    music_files.append(os.path.join(root, file))
        
        if not music_files:
            print(f"âš ï¸  '{music_folder}' í´ë”ì— ìŒì•… íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            print(f"ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í´ë”ë¥¼ ë§Œë“œì„¸ìš”: mkdir {music_folder}")
            print(f"ğŸ’¡ ê·¸ë¦¬ê³  ìŒì•… íŒŒì¼(.mp3, .wav ë“±)ì„ ë„£ì–´ì£¼ì„¸ìš”.\n")
            return
        
        print(f"ğŸ“ {len(music_files)}ê°œì˜ ìŒì•… íŒŒì¼ ë°œê²¬")
        print("="*50 + "\n")
        
        vectors = []
        metadata = []
        
        # ê° ìŒì•… íŒŒì¼ ì²˜ë¦¬
        for idx, audio_path in enumerate(music_files, 1):
            print(f"[{idx}/{len(music_files)}] ì²˜ë¦¬ ì¤‘...")
            
            vector = self.audio_to_vector(audio_path)
            
            if vector is not None:
                vectors.append(vector)
                
                # ë©”íƒ€ë°ì´í„° ìƒì„± (ë‚˜ì¤‘ì— ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì • ê°€ëŠ¥)
                filename = os.path.basename(audio_path)
                title = os.path.splitext(filename)[0]  # í™•ì¥ì ì œê±°
                
                metadata.append({
                    "id": len(metadata),
                    "file_path": audio_path,
                    "title": title,
                    "artist": "Unknown",  # ğŸ”§ ìˆ˜ë™ ì…ë ¥ í•„ìš”
                    "mood": "Unknown",    # ğŸ”§ ìˆ˜ë™ ì…ë ¥ í•„ìš”
                    "genre": "Unknown"    # ğŸ”§ ìˆ˜ë™ ì…ë ¥ í•„ìš”
                })
        
        # ì €ì¥
        if vectors:
            print("="*50)
            print("ğŸ’¾ ì €ì¥ ì¤‘...\n")
            
            vectors_array = np.array(vectors)  # (N, 512)
            
            np.save(f"{output_prefix}.npy", vectors_array)
            print(f"âœ… ë²¡í„° ì €ì¥: {output_prefix}.npy")
            print(f"   Shape: {vectors_array.shape}")
            
            with open(f"{output_prefix}_metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: {output_prefix}_metadata.json")
            
            print(f"\nğŸ‰ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ! ì´ {len(vectors)}ê³¡")
            print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
            print(f"   1. {output_prefix}_metadata.json íŒŒì¼ì„ ì—´ì–´ì„œ")
            print(f"      artist, mood, genreë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”")
            print(f"   2. search_engine.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë§¤ì¹­ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ì„¸ìš”")
        else:
            print("âŒ ì²˜ë¦¬ëœ ìŒì•…ì´ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    print("ğŸµ ìŒì•… ë°ì´í„°ë² ì´ìŠ¤ ë¹Œë”")
    print("="*50 + "\n")
    
    # ì‹¤í–‰
    builder = MusicDatabaseBuilder()
    
    # music í´ë”ì˜ ëª¨ë“  ìŒì•…ì„ ì²˜ë¦¬
    builder.build_database(music_folder="music")