import os
import json
import numpy as np
import pandas as pd
import torch
from transformers import ClapModel, ClapProcessor
import librosa
import warnings
from tqdm import tqdm
warnings.filterwarnings('ignore')

class FMADatabaseBuilder:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"Running on {self.device}...")
        
        print("Loading CLAP (Audio Encoder)...")
        self.clap_model = ClapModel.from_pretrained("laion/clap-htsat-unfused").to(self.device)
        self.clap_processor = ClapProcessor.from_pretrained("laion/clap-htsat-unfused")
        print("âœ… CLAP ë¡œë“œ ì™„ë£Œ\n")
    
    def load_fma_metadata(self, metadata_path="fma_metadata/tracks.csv"):
        """
        FMA ë©”íƒ€ë°ì´í„° ë¡œë“œ ë° íŒŒì‹±
        """
        print("ğŸ“Š FMA ë©”íƒ€ë°ì´í„° ë¡œë”©...")
        
        try:
            # FMA CSVëŠ” multi-level headerë¥¼ ê°€ì§
            tracks = pd.read_csv(metadata_path, index_col=0, header=[0, 1])
            
            metadata_list = []
            
            for track_id in tracks.index:
                try:
                    # track_idë¥¼ 6ìë¦¬ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì˜ˆ: 2 -> "000002")
                    track_id_str = str(track_id).zfill(6)
                    
                    # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                    title = str(tracks.loc[track_id, ('track', 'title')])
                    artist = str(tracks.loc[track_id, ('artist', 'name')])
                    genre_top = str(tracks.loc[track_id, ('track', 'genre_top')])
                    
                    # NaN ì²´í¬
                    if title == 'nan':
                        title = f"Track {track_id_str}"
                    if artist == 'nan':
                        artist = "Unknown Artist"
                    if genre_top == 'nan':
                        genre_top = "Unknown"
                    
                    metadata_list.append({
                        'track_id': track_id_str,
                        'title': title,
                        'artist': artist,
                        'genre': genre_top,
                    })
                    
                except Exception as e:
                    continue
            
            print(f"âœ… {len(metadata_list)}ê³¡ì˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n")
            return metadata_list
            
        except Exception as e:
            print(f"âŒ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def audio_to_vector(self, audio_path, sample_rate=48000, duration=30):
        """
        ìŒì•… íŒŒì¼ -> CLAP ë²¡í„°
        """
        try:
            # ì˜¤ë””ì˜¤ ë¡œë“œ
            audio, sr = librosa.load(audio_path, sr=sample_rate, mono=True)
            
            # í•˜ì´ë¼ì´íŠ¸ ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì¤‘ê°„ 30ì´ˆ)
            max_length = sample_rate * duration
            if len(audio) > max_length:
                start = (len(audio) - max_length) // 2
                audio = audio[start:start + max_length]
            
            # CLAP ì²˜ë¦¬
            inputs = self.clap_processor(
                audios=[audio],
                sampling_rate=sample_rate,
                return_tensors="pt"
            ).to(self.device)
            
            with torch.no_grad():
                outputs = self.clap_model.get_audio_features(**inputs)
            
            # í…ì„œ ì¶”ì¶œ
            if hasattr(outputs, 'audio_embeds'):
                audio_embeds = outputs.audio_embeds
            else:
                audio_embeds = outputs
            
            # ì •ê·œí™”
            audio_embeds = audio_embeds / torch.norm(audio_embeds, p=2, dim=-1, keepdim=True)
            
            return audio_embeds.cpu().numpy().flatten()
            
        except Exception as e:
            return None
    
    def get_audio_path(self, track_id, fma_folder="fma_small"):
        """
        FMA í´ë” êµ¬ì¡°ì— ë§ëŠ” íŒŒì¼ ê²½ë¡œ ìƒì„±
        FMA êµ¬ì¡°: fma_small/000/000002.mp3
        """
        subfolder = track_id[:3]  # ì²˜ìŒ 3ìë¦¬
        audio_path = os.path.join(fma_folder, subfolder, f"{track_id}.mp3")
        return audio_path
    
    def build_database(self, 
                      fma_folder="fma_small",
                      metadata_path="fma_metadata/tracks.csv",
                      output_prefix="music_database",
                      max_songs=100):
        """
        FMA ë°ì´í„°ì…‹ì—ì„œ ìŒì•… ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
        
        Args:
            fma_folder: FMA ì˜¤ë””ì˜¤ íŒŒì¼ í´ë” (fma_small ë“±)
            metadata_path: tracks.csv ê²½ë¡œ
            output_prefix: ì¶œë ¥ íŒŒì¼ ì´ë¦„ prefix
            max_songs: ìµœëŒ€ ì²˜ë¦¬í•  ê³¡ ìˆ˜
        """
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        fma_metadata = self.load_fma_metadata(metadata_path)
        
        if not fma_metadata:
            print("âŒ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        vectors = []
        metadata = []
        
        print(f"ğŸµ ìµœëŒ€ {max_songs}ê³¡ ì²˜ë¦¬ ì‹œì‘...")
        print(f"ğŸ“ ì˜¤ë””ì˜¤ í´ë”: {fma_folder}\n")
        
        # ì§„í–‰ìƒí™© í‘œì‹œ
        processed = 0
        for meta in tqdm(fma_metadata, desc="Processing tracks"):
            if processed >= max_songs:
                break
            
            track_id = meta['track_id']
            audio_path = self.get_audio_path(track_id, fma_folder)
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(audio_path):
                continue
            
            # ë²¡í„° ìƒì„±
            vector = self.audio_to_vector(audio_path)
            
            if vector is not None:
                vectors.append(vector)
                
                metadata.append({
                    "id": len(metadata),
                    "file_path": audio_path,
                    "title": meta['title'],
                    "artist": meta['artist'],
                    "mood": meta['genre'],  # ì¥ë¥´ë¥¼ ë¬´ë“œë¡œ ì‚¬ìš©
                    "genre": meta['genre']
                })
                
                processed += 1
        
        # ì €ì¥
        if vectors:
            print(f"\nğŸ’¾ ì €ì¥ ì¤‘...\n")
            
            vectors_array = np.array(vectors)
            np.save(f"{output_prefix}.npy", vectors_array)
            print(f"âœ… ë²¡í„° ì €ì¥: {output_prefix}.npy")
            print(f"   Shape: {vectors_array.shape}")
            
            with open(f"{output_prefix}_metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: {output_prefix}_metadata.json")
            
            print(f"\nğŸ‰ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ! ì´ {len(vectors)}ê³¡")
        else:
            print("âŒ ì²˜ë¦¬ëœ ìŒì•…ì´ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    print("ğŸµ FMA ìŒì•… ë°ì´í„°ë² ì´ìŠ¤ ë¹Œë”")
    print("="*50 + "\n")
    
    builder = FMADatabaseBuilder()
    
    # FMA Small ë°ì´í„°ì…‹ìœ¼ë¡œ 100ê³¡ ì²˜ë¦¬
    builder.build_database(
        fma_folder="fma_small",  # ë‹¤ìš´ë¡œë“œí•œ FMA í´ë”
        metadata_path="fma_metadata/tracks.csv",  # ë©”íƒ€ë°ì´í„° CSV
        output_prefix="music_database",
        max_songs=100  # ì›í•˜ëŠ” ê³¡ ìˆ˜ (í…ŒìŠ¤íŠ¸: 30, ì‹¤ì „: 500+)
    )